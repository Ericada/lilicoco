import pandas as pd
dfs=pd.read_html("https://rate.bot.com.tw/xrt?Lang=zh-TW")

dfs[0]

cur=dfs[0].ix[:,0:5]
currency=cur["幣別"].iloc[:,0]
currency.str.extract("\((\w+)\)")#extract English word

#google
my_params = {'q': '寒流'}
r = requests.get(google_url, params = my_params)
if r.status_code == requests.codes.ok:
    soup = BeautifulSoup(r.text, 'html.parser')
    items = soup.select('div.g > h3.r > a[href^="/url"]')
    for i in items:
        print("標題：" + i.text)
        print("網址：" + i.get('href'))

import requests
from bs4 import BeautifulSoup
quote_page = "https://law.moj.gov.tw/#NEWS"
res=requests.get(quote_page)
soup=BeautifulSoup(res.text)
html_data=soup.find_all("td")
for i in html_data:
     print(i.text)
     
###############創建新dataframe##############
import numpy as np
import pandas as pd
j=np.zeros(124)
j.shape
aa=pd.DataFrame(j)
aa.columns=["text"]
aa[aa=="教育部公告：預告「客語師資培育資格聘任辦法」草案(預告終止日 107-12-13)"].index


import requests
from bs4 import BeautifulSoup
url = "https://law.moj.gov.tw/LawClass/LawClassListN.aspx?TY=04010006"
ur2="http://www.h2o-china.com/price/view?townid=171&ayear=2015"


request = requests.get(ur2)
content = request.text
soup = BeautifulSoup(content, "html.parser")
print(soup.prettify())
html_data=soup.find_all("td",class_="tabbg01")

import numpy as np
import pandas as pd
jj=np.zeros(33)
j.shape
temp=pd.DataFrame([jj,jj]).T

temp.columns=(["date","text"])
temp["text"]=temp["text"].astype(str)

temp.iloc[:,0]=100

j=0
for i in html_data:
    print(i.text)
    aa[j]=i.text
    j=j+1


aa[3].count(" ")
str = "Line1-abcdef \nLine2-abc \nLine4-abcd"
print (str.split( ))
print (str.split(' '));
aa[3].split()
("民國")+aaa[2]+aaa[3]
temp=temp["date"]
k=0

for ind in range(3,132,4):
    bb[k]=aa[ind]
    k=k+1
temp.iloc[1,1]
len(bb[3].split()    )
si=bb[3].split()[0]
for ind in range(0,33):
    temp.iloc[ind,1]=bb[ind].split()[0]
    str_temp="民國"+bb[ind].split()[2]+bb[ind].split()[3]+bb[ind].split()[4]+bb[ind].split()[5]+bb[ind].split()[6]+bb[ind].split()[7]
    temp.iloc[ind,0]=str_temp
    
temp.to_csv("123.csv",encoding="utf_8_sig")
