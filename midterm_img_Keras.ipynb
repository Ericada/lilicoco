{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midterm_img_Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Tebul3pX0c2F",
        "colab_type": "code",
        "outputId": "fb9b2242-48ef-4e54-9fae-e5c4c81bccbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        }
      },
      "cell_type": "code",
      "source": [
        "'''Basic package'''\n",
        "import os\n",
        "# 告訴系統要第幾張卡被看到。 Ex. 硬體總共有8張顯卡，以下設定只讓系統看到第1張顯卡\n",
        "# 若沒設定，則 Tensorflow 在運行時，預設會把所有卡都佔用\n",
        "# 要看裝置內顯卡數量及目前狀態的話，請在終端機內輸入 \"nvidia-smi\"\n",
        "# 若你的裝置只有一張顯卡可以使用，可以忽略此設定\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "!pip install queue\n",
        "!pip install opencv\n",
        "!pip install pickle\n",
        "\n",
        "import queue\n",
        "import cv2          #影像處理\n",
        "import scipy.misc   #影像處理\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "#繪圖\n",
        "!pip install tqdm\n",
        "from tqdm import tqdm_notebook as tqdm #進度條\n",
        "import matplotlib.pyplot as plt #繪圖\n",
        "%matplotlib inline\n",
        "\n",
        "#影像處理\n",
        "import cv2          \n",
        "import scipy.misc   \n",
        "from IPython.display import Image\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# 自定義 library\n",
        "from generator import data_generators\n",
        "from callbacks import *\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting queue\n",
            "\u001b[31m  Could not find a version that satisfies the requirement queue (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for queue\u001b[0m\n",
            "Collecting opencv\n",
            "\u001b[31m  Could not find a version that satisfies the requirement opencv (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for opencv\u001b[0m\n",
            "Collecting pickle\n",
            "\u001b[31m  Could not find a version that satisfies the requirement pickle (from versions: )\u001b[0m\n",
            "\u001b[31mNo matching distribution found for pickle\u001b[0m\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-27deb78ba845>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# 自定義 library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'generator'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6JzOGgNL0c2M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_data_path = './train/'\n",
        "test_data_path = './testset/'\n",
        "\n",
        "labels = []\n",
        "images = []\n",
        "\n",
        "for root, dirs, files in os.walk(train_data_path):\n",
        "    if len(files) >0 and ('ipynb_checkpoints' not in root): \n",
        "#    if len(files) >0 and root!='where_am_i/train/bedroom/.ipynb_checkpoints':\n",
        "       \n",
        "        print(root)\n",
        "        for f in files:\n",
        "            p = root.split('/')\n",
        "            r = p[-1]\n",
        "            file = root + '/' + f\n",
        "            img = image.load_img(file)\n",
        "            img = img.resize( (128, 128))        \n",
        "            images.append(img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "99yExgY20c2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Data Labeling\n",
        "!cat 'mid_term_mapping.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZTGS_g2Y0c2b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare for testset data import\n",
        "\n",
        "file_list = os.listdir(test_data_path)\n",
        "print(\"number of images: {}\".format(len(file_list)))\n",
        "file_list = file_list[:10]\n",
        "test_images = [cv2.imread(os.path.join(test_data_path, f))[:, :, ::-1] for f in file_list]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V4ph83Sf0c2h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "          rotation_range=0.2,\n",
        "          width_shift_range=0.2,\n",
        "          height_shift_range=0.2,\n",
        "          shear_range=0.2,\n",
        "          zoom_range=0.2,\n",
        "          horizontal_flip=True,\n",
        "          fill_mode='nearest')\n",
        "\n",
        "img = load_img(images)  \n",
        "x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
        "x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3sYgxVE0c2k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the .flow() command below generates batches of randomly transformed images\n",
        "# and saves the results to the `preview/` directory\n",
        "\n",
        "i = 0\n",
        "for batch in datagen.flow(x, \n",
        "                        batch_size=1,\n",
        "                        save_to_dir='~/Desktop/preview',  \n",
        "                        save_prefix='lena', \n",
        "                        save_format='jpg'):\n",
        "    i += 1\n",
        "    if i > 20:\n",
        "        break  # otherwise the generator would loop indefinitely"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EGefVvM50c2n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_of_samples = img_data.shape[0]\n",
        "labels = np.ones((num_of_samples,),dtype='int64') # 一熱\n",
        "\n",
        "index = 0\n",
        "label = 0\n",
        "for data_path in data_path_list:\n",
        "    for dataset in sorted(os.listdir(data_path), key=str.lower): \n",
        "        img_list = os.listdir(data_path+'/'+ dataset)\n",
        "        labels[index: index+len(img_list)] = label\n",
        "        label+=1\n",
        "        index+=len(img_list)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AIajd9m80c2q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_data = np.array(img_data_list)\n",
        "img_data = img_data.astype('float32')\n",
        "img_data /= 255\n",
        "print(img_data.shape)\n",
        "\n",
        "img_data = img_data.reshape(-1, 128, 128, 1) # 128是resize時候自己設定的\n",
        "print(img_data.shape)\n",
        "\n",
        "# One-hot encoding\n",
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "# Shuffle the data\n",
        "from sklearn.utils import shuffle\n",
        "x,y = shuffle(img_data,Y, random_state=2)\n",
        "# Split the data into training set and validation set\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(x, y, test_size=0.25, random_state=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_C7elTIt0c2s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xwSmQAPd0c2y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "shear_range = 0.2,\n",
        "zoom_range = 0.2,\n",
        "horizontal_flip = True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "target_size = (64, 64),\n",
        "batch_size = 32,\n",
        "class_mode = 'binary')\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "target_size = (64, 64),\n",
        "batch_size = 32,\n",
        "class_mode = 'binary')\n",
        "classifier.fit_generator(training_set,\n",
        "steps_per_epoch = 8,\n",
        "epochs = 25,\n",
        "validation_data = test_set,\n",
        "validation_steps = 2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjcWwwSx0c21",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "build cnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6Ygv8Sn0c2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print(model_summary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOp7ZbsuJpYn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_history=model.fit\n",
        "show(train_history)\n",
        "score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T05VdXdAJ2Jw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Predicted_Probability=model.predict\n",
        "show(Predicted_Probability)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}